# Video Similarity Project – 多模態影片相似度比對與侵權偵測系統

## 專案簡介

Video Similarity Project 是一個多模態的影片相似度比對系統，整合了視覺、音訊和文字分析技術來評估兩支影片之間的相似程度。該系統運用深度學習模型與傳統計算機視覺方法，從畫面內容、聲音特徵以及語音轉錄文本等多角度進行比較，幫助使用者偵測影片內容的重複或侵權情形。現在已支持對 YouTube、Bilibili 等主流影音平台影片的比對分析。

## 功能特點

- **多模態分析**：同時分析影片的畫面、音訊和字幕內容，提高比對準確度。
  - 視覺分析：提取影片關鍵幀，計算圖像哈希與深度特徵向量，比較畫面相似度。
  - 音頻分析：提取音頻梅爾頻譜、節奏等特徵及深度音訊嵌入，比較背景音樂或講話聲音相似度。
  - 文本分析：透過 Whisper 將講話內容轉寫為文本，計算語意相似度，比較影片主題內容。

- **影片下載與處理**：內建影片下載模組，支援 YouTube、Bilibili 等多平台影片來源，使用 yt-dlp 作為下載引擎。可自定義下載影片解析度，並將影片按指定時間間隔抽取影像幀進行分析。

- **性能優化**：支援 GPU 加速與多執行緒並行處理。採用快取機制避免重複下載和重複計算特徵，大幅減少處理時間。對長影片自動進行分段分析，降低記憶體消耗風險。

- **相似度評估報告**：輸出詳細的相似度分析結果，包括音訊相似度、畫面相似度、文本相似度，以及加權計算的綜合相似度分數。對於文本內容無意義的情況，系統會自動標註並調整文字相似度權重，確保結果可靠。

## 技術架構

專案採用模組化架構，主要組成部分如下：

- **主程式 (main.py)**：命令列介面入口，負責參數解析和流程控制，協調各模組完成比對。

- **下載器 (utils/downloader.py)**：提供 download_video(url, output_dir) 方法，使用 yt-dlp 下載影片並存為本地檔案，順便下載字幕與影片資訊。

- **影片工具 (utils/video_utils.py)**：提供影片基本資訊獲取和幀提取功能。例如 get_video_info 獲取總幀數和FPS；extract_frames 調用 FFmpeg 抽取視頻幀並保存到磁碟。

- **音頻處理 (core/audio_processor.py)**：負責從影片中提取音訊特徵。包括將影片轉為音訊、提取 MFCC、色度圖等傳統特徵，以及使用預訓練模型獲得深度音訊向量（OpenL3、PANN）等。最終提供 audio_similarity(path1, path2) 計算兩音訊檔的相似度。

- **圖像處理 (core/image_processor.py)**：負責影像特徵計算與視頻相似度。包括感知哈希計算函式 compute_phash 用於快速比較影像相似；以及使用 MobileNet 提取圖像深度特徵向量。提供 video_similarity(frames_list1, frames_list2, duration) 來綜合計算兩影片畫面的相似度。

- **文本處理 (core/text_processor.py)**：負責語音轉錄與文字比對。使用 Faster-Whisper 模型將影片音訊轉為文字（自動偵測語言並分段避免長音訊問題），再用 SentenceTransformer 計算文字語意相似度。提供 transcribe_audio(audio_path, ...) 取得轉錄文本，text_similarity(text1, text2) 返回文本相似度分數。

- **相似度整合 (core/similarity.py)**：綜合各模態計算最終相似度的模組。函式 calculate_overall_similarity(audio1, audio2, frames1, frames2, text1, text2, video_duration) 將音訊、影像、文字的相似度按照可配置權重加權平均，計算出綜合相似度。同時提供 display_similarity_results 將結果以易讀表格形式列出。

- **日誌與環境 (utils/logger.py, utils/dependencies.py)**：提供統一的日誌記錄器，用於輸出資訊、警告和錯誤訊息；依賴檢查模組會在程式啟動時檢查 ffmpeg、yt-dlp、CUDA 等環境是否可用。

## 專案結構

```
video_similarity_project/
├─ core/               # 核心處理模組
│   ├─ audio_processor.py      # 音頻特徵提取與相似度計算
│   ├─ image_processor.py      # 圖像特徵提取與相似度計算
│   ├─ text_processor.py       # 語音轉錄與文字相似度計算
│   └─ similarity.py           # 多模態相似度融合與結果輸出
├─ utils/              # 實用工具模組
│   ├─ downloader.py           # 影片下載與命名工具
│   ├─ video_utils.py          # 幀提取、影片資訊獲取
│   ├─ audio_cleaner.py        # 音訊過濾（如降噪、靜音偵測）*(若存在)*
│   ├─ gpu_utils.py            # GPU 記憶體管理工具
│   ├─ logger.py               # 日誌紀錄設定
│   └─ dependencies.py         # 執行環境依賴檢查
├─ panns_inference/     # 第三方預訓練模型相關程式 (PANN 音訊模型)
│   ├─ inference.py            # 簡易推理介面
│   ├─ models.py               # 模型架構定義 (CNN14 等)
│   ├─ pytorch_utils.py        # PANN 模型所需的 PyTorch 工具
│   └─ config.py               # PANN 模組配置
├─ downloads/          # *執行後產生:* 影片與幀暫存資料夾（可自定義路徑）
├─ feature_cache/      # *執行後產生:* 音訊特徵快取資料夾（可自定義路徑）
├─ requirements.txt    # Python 相依套件清單
└─ README.md           # 說明文件 (本檔案)
```

## 安裝與環境需求

### 環境要求：
- Python 3.8 或以上版本
- 建議具備 NVIDIA GPU 以及已安裝 CUDA 11+ 和 cuDNN，以使用GPU加速
- 已安裝 FFmpeg 工具（用于视频和音频處理）
- 已安裝 yt-dlp 工具（用于下載影片）

### 安裝步驟：

1. 取得程式碼：克隆此專案倉庫至本地
   ```bash
   git clone https://github.com/terrylu930119/video_similarity_project.git
   cd video_similarity_project
   ```

2. 建立虛擬環境（可選）：為避免依賴衝突，建議創建 Python 虛擬環境
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac 使用
   venv\Scripts\activate      # Windows 使用
   ```

3. 安裝依賴套件：使用 pip 安裝所需的 Python 套件
   ```bash
   pip install -r requirements.txt
   ```

注意：首次執行時，程式會自動下載所需的機器學習模型（Whisper 等，約數百MB至1GB），請確保網路通暢。

### 準備外部工具：
確認已安裝以下系統軟體並在 PATH 中：
- FFmpeg：視頻處理工具。如未安裝，請參考其官方說明。在 Linux 上可用 apt-get install ffmpeg 安裝。
- yt-dlp：多平台視頻下載工具。如未安裝，可執行 pip install yt-dlp 安裝最新版本。

## 使用方式

安裝完成後，可通過命令列介面使用本工具：

### 基本用法：
在終端執行 main.py 並提供參考影片和一個或多個要比對的影片連結：
```bash
python main.py --ref <參考影片URL> --comp <待比對影片URL1> <待比對影片URL2> ... [選項]
```

### 必填參數：
- `--ref`：參考影片的網址 (URL)
- `--comp`：一個或多個欲比對影片的網址，可以提供多個

### 選用參數：
- `--output`：指定下載及處理的輸出目錄，預設為 downloads
- `--cache`：指定特徵快取目錄，預設為 feature_cache
- `--interval`：幀提取的時間間隔（秒），可設定為'auto'
- `--keep`：加入此參數則保留中間下載的影音及提取的特徵文件（不自動刪除）

例如，要將參考影片與兩支影片進行比對，可執行：
```bash
python main.py --ref "https://www.youtube.com/watch?v=xxxxxxxx" \
               --comp "https://www.youtube.com/watch?v=yyyyyyyy" "https://www.bilibili.com/video/BVXXXXX"
```

### 結果解讀：
比對完成後，終端輸出表格包含每個待比對影片相對於參考影片的相似度分數，例如：

```
=== 相似度比對結果 ===
參考影片: https://youtu.be/abc123...

比對結果:
------------------------------------------------------------------------------------------------------------
影片連結                                                    音訊相似度   畫面相似度   內容相似度   綜合相似度
------------------------------------------------------------------------------------------------------------
https://youtu.be/def456...                                   0.8457       0.9123       0.0000*      0.8804
https://www.bilibili.com/video/BVXXXXX...                    0.6578       0.7012       0.7345       0.6939
------------------------------------------------------------------------------------------------------------

註: * 表示該影片的文本內容被判定為無意義，其文本相似度權重已被重新分配到音訊和畫面相似度

#### 相似度分數解讀指引（音頻 × 畫面 × 文本）

本系統使用多模態比對方式，針對「音頻」、「畫面」、「轉錄文本」三個維度進行相似度評估。以下為各項分數的解讀說明，分數範圍皆為 0.0 ~ 1.0，分數越高代表內容越相似。

---

**音頻相似度解讀表（Perceptual Audio Similarity）**

| 分數範圍      | 判定標籤   | 解釋說明                                               |
|:-------------:|:---------:|:------------------------------------------------------|
| ≥ 0.88        | 極高相似   | 聲音結構、音色、節奏與語義一致，極可能為同源影片或轉碼版本 |
| 0.75 – 0.88   |  高相似    | 多數特徵重合，可能為不同來源、混音版、現場翻唱等變體      |
| 0.60 – 0.75   | 中度相似   | 屬於相同曲風或相似片段重疊，但非同一原始內容             |
| 0.40 – 0.60   | 低度相似   | 僅有少數特徵吻合，可視為不同來源                        |
| < 0.40        | 無明顯關聯 | 聲音特徵差異明顯，判定為完全不同音源                     |

---

**畫面相似度解讀表（Video Frame Similarity）**

| 分數範圍      | 判定標籤   | 解釋說明                                               |
|:-------------:|:---------:|:------------------------------------------------------|
| ≥ 0.90        | 極高相似   | 畫面幾乎一致，疑似轉載或語音更換後重製                   |
| 0.82 – 0.90   | 高相似     | 多數畫面重合，僅有輕微剪輯或過渡效果                     |
| 0.70 – 0.82   | 中高相似   | 主體一致性高，可能為剪輯版、語言替換或平台版本差異        |
| 0.55 – 0.70   | 中度相似   | 局部共用元素，含片頭、插圖或共用素材                     |
| 0.35 – 0.55   | 低度相似   | 僅小比例畫面一致，整體風格不同                          |
| < 0.35        | 無明顯關聯 | 畫面、節奏與色彩特徵皆不同，無實質重合                   |

---

**文本相似度解讀表（Transcript Semantic Similarity）**

| 分數範圍      | 判定標籤   | 解釋說明                                               |
|:-------------:|:---------:|:------------------------------------------------------|
| ≥ 0.85        | 高度相似   | 內容幾乎相同，疑似翻譯、抄襲或改寫                       |
| 0.70 – 0.85   | 中高相似   | 主題一致，語句結構不同但語意接近                         |
| 0.50 – 0.70   | 中度相似   | 有共用資料來源或敘述主題相同                             |
| 0.30 – 0.50   | 低度相似   | 僅有少量概念重合，非同一內容改寫                         |
| < 0.30        | 無明顯關聯 | 幾乎無語意重疊，可視為完全不同文本                       |

---

> **註**：分數僅供參考，實際判斷仍需結合影片內容與人工審查。

## 資料夾與模組說明

- **downloads/**：預設的影片下載及處理輸出目錄。執行比對時，下載的原始影片文件、擷取的幀圖片、轉錄的字幕文字等都儲存在此資料夾下（按照影片ID區分子目錄）。如果不加 --keep 參數，程式在完成後會自動清理此資料夾。

- **feature_cache/**：預設的音訊特徵快取目錄。音頻分析模組會將提取的特徵向量快取到此，例如 .npy 或 .pkl 檔案，以加速重複影片的比對。同樣地，若未指定 --keep，程式結束時會刪除此目錄釋放空間。

- **core/**：核心代碼所在目錄，包含多模態分析的主要程式碼：
  - audio_processor.py：音訊處理模組，包含音訊特徵提取函式（如 MFCC、chroma）、深度模型提取（PANN, OpenL3）及 audio_similarity 計算函式。
  - image_processor.py：圖像處理模組，提供 compute_phash、compute_batch_embeddings 等函式計算影像哈希與深度特徵，以及兩階段的 video_similarity 計算流程。
  - text_processor.py：文本處理模組，提供音訊轉錄函式 transcribe_audio（內部調用 Whisper 模型）和文本相似度計算函式 text_similarity（調用 sentence-transformers 模型計算語意相似度）。
  - similarity.py：相似度融合模組，定義 calculate_overall_similarity 將音訊、圖像、文本相似度按照權重合成總分，並包含結果格式化輸出的函式。

- **utils/**：工具類模組目錄，提供整個系統運作所需的輔助功能：
  - downloader.py：影片下載與命名工具，使用 yt-dlp 實現下載，並提供生成安全文件名的方法。
  - video_utils.py：視頻相關工具，負責驗證影片文件、提取幀影像、取得影片基本資訊等。
  - audio_cleaner.py：音訊預處理工具，用於消除靜音片段或背景噪音等（假如存在此檔，根據需要清理音訊訊號，提高後續特徵提取的準確性）。
  - gpu_utils.py：GPU 記憶體管理工具，可釋放顯存快取，以避免長時間運行佔用過多GPU記憶。
  - logger.py：日誌模組，設定統一的 logger 用於打印資訊、警告、錯誤。方便在終端觀察處理流程和調試。
  - dependencies.py：依賴檢查與安裝。提供檢查 ffmpeg/yt-dlp 是否安裝、CUDA 是否可用等函式，在啟動時被呼叫以提示使用者安裝缺失的依賴。

- **panns_inference/**：內含預訓練環境音分類模型（PANN: Pretrained Audio Neural Networks）的相關程式碼。本專案使用其中的 Cnn14 模型來提取音訊的環境聲音特徵向量，用於輔助音訊相似度計算。該資料夾下包括模型定義、權重下載/載入以及推理所需的工具程式。

### 其他文件：
- requirements.txt：列出專案所需安裝的 Python 套件及版本。如 PyTorch、torchvision、librosa、yt-dlp、faster-whisper 等。
- LICENSE：專案授權協議文件（默認為 MIT License）。
- README.md：專案說明文檔，即本文件，提供使用指南和技術細節。

## 未來可能的計劃

此專案仍在持續改進中，以下是規劃中的一些新功能與優化方向：

- 支援更多影片平台：擴充下載器以支援更多影音平台的影片網址（如 Vimeo、Facebook 等），增強適用範圍。
- 提升處理速度：進一步優化算法和並行策略，例如利用多GPU同時計算、減少特徵維度以加快比對等，力求在保證準確率的前提下降低運算時間。
- 改進相似度算法：探索更先進的影片指紋技術或深度學習比對模型，引入學習型的特徵融合策略，減少人工設定參數帶來的局限。
- 開發圖形介面：提供友好的使用者介面，如 Web 儀表板或桌面應用，方便非技術用戶使用本工具上傳影片並查看結果。
- 支援批量處理：允許使用者一次性提交大量影片做交叉比對，系統自動列出每對影片的相似度矩陣，方便進行資料庫重複內容掃描。

## 貢獻指南

歡迎社群開發者一同參與本專案！如果您有新的想法、發現了問題或優化了程式，請按照以下步驟貢獻：

1. 在 GitHub 上 Fork 本倉庫，取得一份副本到您的帳戶下。
2. 基於 main 分支創建一個新的開發分支：
   ```bash
   git checkout -b feature/YourFeatureName
   ```
3. 進行您的修改或新增功能，並適時提交代碼：
   ```bash
   git commit -m "Add: 說明您的修改內容"
   ```
4. 將您的分支推送到自己的 Fork 倉庫：
   ```bash
   git push origin feature/YourFeatureName
   ```
5. 前往原始倉庫建立 Pull Request，描述您的更改內容和動機。

專案管理者會儘快審查您的更改，討論後合併或提出修改建議。

在提交 Pull Request 之前，請確保您的程式通過基本測試，遵循專案的代碼風格，並附上必要的說明文件更新（如果您的更改影響了使用方式或模組介面）。

## 授權與引用

本專案採用 MIT 授權條款。這意味著您可以自由使用、修改和發布本程式碼，但需在程式的衍生版本中包含原始授權聲明和版權通知。

如果您在學術研究中使用了本工具，歡迎在論文中引用本專案（您可以引用本 GitHub 倉庫 URL）。同時也鼓勵您與我們分享您的研究成果或反饋，以促進專案的持續改進。

祝您使用愉快，期待您的貢獻！ 