import gc
import os
import re
import torch
import whisper
import torchaudio
from math import ceil
from itertools import groupby
from collections import Counter
from utils.logger import logger
from utils.gpu_utils import gpu_manager
from core.audio_processor import load_audio
from concurrent.futures import ThreadPoolExecutor
from utils.downloader import generate_safe_filename
from sentence_transformers import SentenceTransformer, util
from utils.audio_cleaner import load_and_clean_audio
from faster_whisper import WhisperModel


# å…¨åŸŸæ¨¡å‹è®Šæ•¸
_whisper_model = None
_sentence_transformer = None

def get_whisper_model():
    """å–å¾—æˆ–è¼‰å…¥ faster-whisper æ¨¡å‹"""
    global _whisper_model
    if _whisper_model is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info("æ­£åœ¨è¼‰å…¥ faster-whisper medium æ¨¡å‹...")
        compute_type = "float16" if torch.cuda.is_available() else "int8"
        _whisper_model = WhisperModel("medium", device=device, compute_type=compute_type)
        logger.info("Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ")
    return _whisper_model

def get_sentence_transformer():
    """
    ç²å–å…¨åŸŸ SentenceTransformer æ¨¡å‹å¯¦ä¾‹ï¼Œå¦‚æœæœªè¼‰å…¥å‰‡é€²è¡Œè¼‰å…¥
    """
    global _sentence_transformer
    if _sentence_transformer is None:
        logger.info("æ­£åœ¨è¼‰å…¥ SentenceTransformer æ¨¡å‹...")
        _sentence_transformer = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
        # å¦‚æœæœ‰ GPUï¼Œå°‡æ¨¡å‹ç§»è‡³ GPU
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            logger.info("å°‡ SentenceTransformer æ¨¡å‹ç§»è‡³ GPU")
            _sentence_transformer = _sentence_transformer.to(torch.device('cuda'))
        logger.info("SentenceTransformer æ¨¡å‹è¼‰å…¥å®Œæˆ")
    return _sentence_transformer

def get_subtitle_language(filename: str) -> str:
    """
    å¾å­—å¹•æ–‡ä»¶åä¸­æå–èªè¨€ä»£ç¢¼
    
    åƒæ•¸:
        filename: å­—å¹•æ–‡ä»¶å
    
    è¿”å›:
        èªè¨€ä»£ç¢¼ï¼Œå¦‚æœç„¡æ³•æå–å‰‡è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    try:
        # å¾æ–‡ä»¶åä¸­æå–èªè¨€ä»£ç¢¼
        # æ ¼å¼ï¼šsafe_filename.language.vtt
        parts = filename.split('.')
        if len(parts) >= 3:
            return parts[-2]  # è¿”å›å€’æ•¸ç¬¬äºŒå€‹éƒ¨åˆ†ï¼ˆèªè¨€ä»£ç¢¼ï¼‰
        return ""
    except Exception as e:
        logger.error(f"å¾æ–‡ä»¶åæå–èªè¨€ä»£ç¢¼æ™‚å‡ºéŒ¯: {str(e)}")
        return ""

def get_preferred_subtitle(subtitle_files: list, safe_filename: str) -> str:
    """
    æ ¹æ“šèªè¨€å„ªå…ˆé †åºé¸æ“‡æœ€é©åˆçš„å­—å¹•æ–‡ä»¶
    
    åƒæ•¸:
        subtitle_files: å­—å¹•æ–‡ä»¶åˆ—è¡¨
        safe_filename: å®‰å…¨çš„æª”æ¡ˆåç¨±
    
    è¿”å›:
        é¸æ“‡çš„å­—å¹•æ–‡ä»¶åï¼Œå¦‚æœæ²’æœ‰åˆé©çš„å­—å¹•å‰‡è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    # èªè¨€å„ªå…ˆé †åº
    language_priority = ['zh-Hant', 'zh-HK', 'zh-TW', 'zh', 'en', 'en-US', 'en-GB']
    
    # é¦–å…ˆå˜—è©¦æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„æ–‡ä»¶å
    exact_matches = [f for f in subtitle_files if f.startswith(safe_filename)]
    if exact_matches:
        subtitle_files = exact_matches
    
    # æŒ‰å„ªå…ˆé †åºæª¢æŸ¥èªè¨€
    for lang in language_priority:
        for file in subtitle_files:
            if lang in file:
                return file
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°å„ªå…ˆèªè¨€ï¼Œè¿”å›ç¬¬ä¸€å€‹å¯ç”¨çš„å­—å¹•
    return subtitle_files[0] if subtitle_files else ""

def extract_video_id_from_url(url: str) -> str:
    """å¾ YouTube URL ä¸­æå–å½±ç‰‡ ID å’Œæ’­æ”¾æ¸…å–®ç´¢å¼•"""
    try:
        # æå–å½±ç‰‡ ID
        if 'youtu.be/' in url:
            video_id = url.split('youtu.be/')[-1].split('?')[0]
        elif 'youtube.com/watch' in url:
            from urllib.parse import parse_qs, urlparse
            parsed_url = urlparse(url)
            video_id = parse_qs(parsed_url.query)['v'][0]
        else:
            logger.error(f"ä¸æ”¯æ´çš„ YouTube URL æ ¼å¼: {url}")
            return ""
            
        # ç§»é™¤é¡å¤–çš„åƒæ•¸
        video_id = video_id.split('&')[0]
        
        # æå–æ’­æ”¾æ¸…å–®ç´¢å¼•
        index_match = re.search(r'index=(\d+)', url)
        playlist_index = index_match.group(1) if index_match else ""
        
        # çµ„åˆæª”æ¡ˆåç¨±ï¼švideoId_index
        return f"{video_id}_{playlist_index}" if playlist_index else video_id
        
    except Exception as e:
        logger.error(f"å¾ URL æå–å½±ç‰‡ ID æ™‚å‡ºéŒ¯: {str(e)}")
        return ""

def extract_subtitles(video_url: str, output_dir: str) -> str:
    """
    å¾å·²ä¸‹è¼‰çš„å­—å¹•æ–‡ä»¶ä¸­è®€å–å­—å¹•
    
    åƒæ•¸:
        video_url: å½±ç‰‡ URL
        output_dir: è¼¸å‡ºç›®éŒ„
    
    è¿”å›:
        å­—å¹•æ–‡æœ¬ï¼Œå¦‚æœæ²’æœ‰å­—å¹•å‰‡è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    try:
        # ä½¿ç”¨èˆ‡ä¸‹è¼‰å™¨ç›¸åŒçš„æª”æ¡ˆå‘½åè¦å‰‡
        safe_filename = generate_safe_filename(video_url)
            
        # æª¢æŸ¥å­—å¹•æ–‡ä»¶
        subtitle_files = [f for f in os.listdir(output_dir) if f.startswith(safe_filename) and f.endswith('.vtt')]
        
        if not subtitle_files:
            logger.info("æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return ""
            
        # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å­—å¹•èªè¨€
        available_languages = [get_subtitle_language(f) for f in subtitle_files]
        logger.info(f"å¯ç”¨çš„å­—å¹•èªè¨€: {', '.join(available_languages)}")
        
        # é¸æ“‡å„ªå…ˆèªè¨€çš„å­—å¹•
        preferred_subtitle = get_preferred_subtitle(subtitle_files, safe_filename)
        if not preferred_subtitle:
            logger.info("æœªæ‰¾åˆ°åˆé©çš„å­—å¹•æ–‡ä»¶")
            return ""
            
        subtitle_path = os.path.join(output_dir, preferred_subtitle)
        subtitle_lang = get_subtitle_language(preferred_subtitle)
        logger.info(f"ä½¿ç”¨ {subtitle_lang} å­—å¹•")
        
        try:
            with open(subtitle_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            if not content.strip():
                logger.warning("å­—å¹•å…§å®¹ç‚ºç©º")
                return ""
                
            # è™•ç† VTT æ ¼å¼å­—å¹•ï¼Œç§»é™¤æ™‚é–“æˆ³å’Œå…¶ä»–æ ¼å¼ä¿¡æ¯
            lines = content.split('\n')
            cleaned_lines = []
            for line in lines:
                # è·³é WebVTT é ­éƒ¨ä¿¡æ¯
                if line.startswith('WEBVTT') or '-->' in line or line.strip().isdigit():
                    continue
                # ä¿ç•™éç©ºçš„æ–‡æœ¬è¡Œ
                if line.strip():
                    cleaned_lines.append(line.strip())
            
            cleaned_content = ' '.join(cleaned_lines)
            logger.info(f"æˆåŠŸè®€å–å­—å¹•ï¼Œé•·åº¦: {len(cleaned_content)} å­—ç¬¦")
            return cleaned_content
            
        except Exception as e:
            logger.error(f"è®€å–å­—å¹•æ–‡ä»¶æ™‚å‡ºéŒ¯: {str(e)}")
            return ""
            
    except Exception as e:
        logger.error(f"æå–å­—å¹•æ™‚å‡ºéŒ¯: {str(e)}")
        return ""

# legacy use: ä¿ç•™èˆŠç‰ˆå¾Œè™•ç†é‚è¼¯ï¼Œé è¨­æµç¨‹ä¸­ä¸å†å‘¼å«
def post_process_transcript(text: str, language: str = None) -> str:
    """
    å¾Œè™•ç†è½‰éŒ„æ–‡æœ¬ï¼Œè™•ç†é‡è¤‡å’Œæ ¼å¼åŒ–å•é¡Œ
    
    åƒæ•¸:
        text: åŸå§‹è½‰éŒ„æ–‡æœ¬
        language: èªè¨€ä»£ç¢¼ï¼ˆ'ja', 'zh', 'en' ç­‰ï¼‰
    """
    if not text:
        return text

    # å®šç¾©èªè¨€ç‰¹å®šçš„æ¨™é»ç¬¦è™Ÿå’Œè¦å‰‡
    LANGUAGE_RULES = {
        'ja': {
            'sentence_end': 'ã€‚ï¼ï¼Ÿ',
            'comma': 'ã€',
            'particles': 'ã¯ãŒã§ã«ã¨ã¸ã‚‚ã‚’',
            'end_mark': 'ã€‚',
            'comma_mark': 'ã€'
        },
        'zh': {
            'sentence_end': 'ã€‚ï¼ï¼Ÿ',
            'comma': 'ï¼Œã€',
            'particles': 'çš„åœ°å¾—äº†è‘—é',
            'end_mark': 'ã€‚',
            'comma_mark': 'ï¼Œ'
        },
        'en': {
            'sentence_end': '.!?',
            'comma': ',',
            'particles': 'and or but in on at with to',
            'end_mark': '.',
            'comma_mark': ','
        }
    }
    
    # ç²å–èªè¨€è¦å‰‡ï¼Œå¦‚æœæ²’æœ‰ç‰¹å®šè¦å‰‡å‰‡ä½¿ç”¨è‹±æ–‡è¦å‰‡
    rules = LANGUAGE_RULES.get(language, LANGUAGE_RULES['en'])
    
    def remove_consecutive_duplicates(text):
        """ç§»é™¤é€£çºŒé‡è¤‡çš„å…§å®¹"""
        # æ ¹æ“šèªè¨€é¸æ“‡åˆ†å‰²æ–¹å¼
        if language in ['ja', 'zh']:  # ä¸­æ—¥æ–‡æŒ‰å­—ç¬¦åˆ†å‰²
            words = list(text)
        else:  # å…¶ä»–èªè¨€æŒ‰ç©ºæ ¼åˆ†å‰²
            words = text.split()
        
        # ç§»é™¤é€£çºŒé‡è¤‡ï¼Œä½†ä¿ç•™æœ‰æ„ç¾©çš„é‡è¤‡ï¼ˆå¦‚æ“¬è²è©ï¼‰
        result = []
        for word, group in groupby(words):
            count = len(list(group))
            # å¦‚æœæ˜¯çŸ­è©ï¼ˆ1-2å­—ç¬¦ï¼‰ä¸”é‡è¤‡æ¬¡æ•¸å°æ–¼ç­‰æ–¼3ï¼Œä¿ç•™é‡è¤‡
            if (len(word) <= 2 and count <= 3) or count == 1:
                result.extend([word] * count)
            else:
                result.append(word)
        
        # é‡æ–°çµ„åˆæ–‡æœ¬
        if language in ['ja', 'zh']:
            return ''.join(result)
        return ' '.join(result)
    
    def remove_long_duplicates(text):
        """ç§»é™¤é•·ç‰‡æ®µé‡è¤‡"""
        # å°æ–¼ä¸åŒèªè¨€ä½¿ç”¨ä¸åŒçš„æœ€å°é•·åº¦
        min_length = 2 if language in ['ja', 'zh'] else 3
        max_length = 20
        
        for length in range(max_length, min_length, -1):
            pattern = f'(.{{{length}}})\\1+'
            text = re.sub(pattern, r'\1', text)
        return text
    
    def add_punctuation(text):
        """æ·»åŠ é©ç•¶çš„æ¨™é»ç¬¦è™Ÿ"""
        # åœ¨å¥å­çµå°¾æ·»åŠ å¥è™Ÿ
        end_pattern = f'([^{rules["sentence_end"]}\\s])([^\\w{rules["sentence_end"]}]*)$'
        text = re.sub(end_pattern, f'\\1{rules["end_mark"]}\\2', text)
        
        # åœ¨è‡ªç„¶åœé “è™•æ·»åŠ é€—è™Ÿ
        if language in ['ja', 'zh']:
            # åœ¨ç‰¹å®šåŠ©è©å‰æ·»åŠ é€—è™Ÿ
            particle_pattern = f'([^{rules["comma"]}{rules["sentence_end"]}\\s])([{rules["particles"]}])'
            text = re.sub(particle_pattern, f'\\1{rules["comma_mark"]}\\2', text)
        else:
            # åœ¨é€£æ¥è©å‰æ·»åŠ é€—è™Ÿ
            for particle in rules["particles"].split():
                text = re.sub(f'\\s+{particle}\\s+', f'{rules["comma_mark"]} {particle} ', text)
        
        return text
    
    # åŸ·è¡Œè™•ç†æ­¥é©Ÿ
    text = remove_consecutive_duplicates(text)
    text = remove_long_duplicates(text)
    text = add_punctuation(text)
    
    # æœ€å¾Œçš„æ¸…ç†
    # ç§»é™¤å¤šé¤˜çš„ç©ºæ ¼
    if language in ['ja', 'zh']:
        text = re.sub(r'\s+', '', text)
    else:
        text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤é‡è¤‡çš„æ¨™é»ç¬¦è™Ÿ
    text = re.sub(f'[{rules["sentence_end"]}{rules["comma"]}]+', lambda m: m.group(0)[0], text)
    
    return text.strip()

def split_audio_for_transcription(audio_path: str, segment_duration: int = 30, overlap: int = 2, use_silence_detection: bool = True, merge_gap_threshold: int = 1000, min_segment_duration: int = 3) -> list:
    """
    å°‡éŸ³é »åˆ†å‰²æˆå°ç‰‡æ®µç”¨æ–¼è½‰éŒ„ï¼Œæ”¯æŒé‡ç–Šè™•ç†å’ŒéœéŸ³æ–·é»åˆ‡å‰²
    
    åƒæ•¸:
        audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
        segment_duration: æ¯å€‹ç‰‡æ®µçš„æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
        overlap: é‡ç–Šæ™‚é–“ï¼ˆç§’ï¼‰
        use_silence_detection: æ˜¯å¦ä½¿ç”¨éœéŸ³æ–·é»åˆ‡å‰²
        merge_gap_threshold: åˆä½µéœéŸ³æ®µçš„é–¾å€¼ï¼ˆæ¯«ç§’ï¼‰
        min_segment_duration: æœ€å°ç‰‡æ®µæ™‚é•·ï¼ˆç§’ï¼‰
    """
    try:
        # æª¢æŸ¥éŸ³é »æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            logger.error(f"éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return []
            
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„
        temp_dir = os.path.join(os.path.dirname(audio_path), "temp_segments")
        os.makedirs(temp_dir, exist_ok=True)
        
        # ä½¿ç”¨ librosa è¼‰å…¥éŸ³é »ï¼ˆæ›´ç¯€çœå…§å­˜ï¼‰
        try:
            import librosa
            import soundfile as sf
            y, sr = librosa.load(audio_path, sr=None, mono=True)
            duration = len(y) / sr
            logger.info(f"éŸ³é »ç¸½é•·åº¦: {duration:.2f} ç§’")
            
            # è¨ˆç®—åˆ†æ®µ
            samples_per_segment = int(segment_duration * sr)
            overlap_samples = int(overlap * sr)
            num_segments = ceil((len(y) - overlap_samples) / (samples_per_segment - overlap_samples))
            
            def process_segment(i):
                try:
                    # è¨ˆç®—ç‰‡æ®µçš„èµ·å§‹å’ŒçµæŸä½ç½®
                    start = int(i * (samples_per_segment - overlap_samples))
                    end = int(min(start + samples_per_segment, len(y)))

                    # æå–ç‰‡æ®µ
                    segment = y[start:end]

                    # ğŸ” åŠ é€™è¡Œä¾†æª¢æŸ¥ç‰‡æ®µæ˜¯å¦æœ‰è²éŸ³
                    import numpy as np
                    print(f"[DEBUG] segment_{i:03d}: max_volume={np.abs(segment).max():.4f}, length={len(segment)}")

                    # ä¿å­˜ç‰‡æ®µ
                    segment_path = os.path.join(temp_dir, f"segment_{i:03d}.wav")
                    sf.write(segment_path, segment, sr)

                    # é¡¯ç¤ºæª”æ¡ˆå¤§å°
                    print(f"[DEBUG] segment_{i:03d}.wav saved, size: {os.path.getsize(segment_path)} bytes")

                    logger.info(f"å·²ä¿å­˜ç‰‡æ®µ {i+1}/{num_segments}")
                    return segment_path

                except Exception as e:
                    logger.error(f"è™•ç†ç‰‡æ®µ {i+1} æ™‚å‡ºéŒ¯: {str(e)}")
                    return None


            
            # æ ¹æ“šç³»çµ±è³‡æºå‹•æ…‹èª¿æ•´ç·šç¨‹æ•¸
            import psutil
            cpu_count = psutil.cpu_count()
            max_workers = min(cpu_count - 1, 4)  # ä¿ç•™ä¸€å€‹CPUæ ¸å¿ƒçµ¦ç³»çµ±
            
            # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†ç‰‡æ®µ
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                segment_files = list(executor.map(process_segment, range(num_segments)))
            
            # éæ¿¾æ‰å¤±æ•—çš„ç‰‡æ®µ
            valid_segments = [f for f in segment_files if f is not None]
            
            if not valid_segments:
                logger.error("æ²’æœ‰æˆåŠŸç”Ÿæˆçš„éŸ³é »ç‰‡æ®µ")
                return []
                
            return valid_segments
            
        except ImportError:
            logger.warning("librosa ä¸å¯ç”¨ï¼Œå˜—è©¦ä½¿ç”¨ torchaudio...")
            # å¦‚æœ librosa ä¸å¯ç”¨ï¼Œå›é€€åˆ° torchaudio
            waveform, sr = torchaudio.load(audio_path)
            if waveform.size(0) > 1:  # å¦‚æœæ˜¯å¤šè²é“ï¼Œè½‰æ›ç‚ºå–®è²é“
                waveform = waveform.mean(dim=0, keepdim=True)
                
            duration = waveform.size(1) / sr
            logger.info(f"éŸ³é »ç¸½é•·åº¦: {duration:.2f} ç§’")
            
            # è¨ˆç®—åˆ†æ®µ
            samples_per_segment = segment_duration * sr
            overlap_samples = overlap * sr
            num_segments = ceil((waveform.size(1) - overlap_samples) / (samples_per_segment - overlap_samples))
            
            def process_segment(i):
                try:
                    start = int(i * (samples_per_segment - overlap_samples))
                    end = int(min(start + samples_per_segment, waveform.size(1)))
                    segment = waveform[:, start:end]
                    segment_path = os.path.join(temp_dir, f"segment_{i:03d}.wav")
                    torchaudio.save(segment_path, segment, sr)
                    logger.info(f"å·²ä¿å­˜ç‰‡æ®µ {i+1}/{num_segments}")
                    return segment_path
                except Exception as e:
                    logger.error(f"è™•ç†ç‰‡æ®µ {i+1} æ™‚å‡ºéŒ¯: {str(e)}")
                    return None
            
            # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†ç‰‡æ®µ
            with ThreadPoolExecutor(max_workers=4) as executor:
                segment_files = list(executor.map(process_segment, range(num_segments)))
            
            # éæ¿¾æ‰å¤±æ•—çš„ç‰‡æ®µ
            valid_segments = [f for f in segment_files if f is not None]
            
            if not valid_segments:
                logger.error("æ²’æœ‰æˆåŠŸç”Ÿæˆçš„éŸ³é »ç‰‡æ®µ")
                return []
                
            return valid_segments
            
    except Exception as e:
        logger.error(f"åˆ†å‰²éŸ³é »æ™‚å‡ºéŒ¯: {str(e)}")
        return []
    finally:
        # æ¸…ç†å…§å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()  # å¼·åˆ¶åƒåœ¾å›æ”¶

def merge_transcripts(transcripts: list) -> str:
    """
    åˆä½µå¤šå€‹è½‰éŒ„æ–‡æœ¬
    """
    return " ".join(filter(None, transcripts))

def transcribe_audio(audio_path: str, video_url: str = None, output_dir: str = None,
                     use_silence_detection: bool = True, merge_gap_threshold: int = 1000,
                     min_segment_duration: int = 3, use_source_separation: bool = True,
                     track_languages: bool = True) -> str:
    """
    ä½¿ç”¨ Faster-Whisper é€²è¡ŒèªéŸ³è½‰éŒ„ï¼Œæ”¯æ´èªè¨€è‡ªå‹•åµæ¸¬èˆ‡æ®µè½èªç³»è¨˜éŒ„ã€‚
    """
    try:
        # è‹¥å·²æœ‰è½‰éŒ„æª”æ¡ˆ
        if output_dir:
            transcript_path = os.path.join(output_dir, os.path.basename(audio_path).replace('.wav', '_transcript.txt'))
            if os.path.exists(transcript_path):
                try:
                    with open(transcript_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():
                            logger.info(f"æ‰¾åˆ°ç¾æœ‰è½‰éŒ„æ–‡ä»¶ï¼š{transcript_path}")
                            return content.strip()
                except Exception as e:
                    logger.warning(f"è®€å–ç¾æœ‰è½‰éŒ„æ–‡ä»¶æ™‚å‡ºéŒ¯ï¼š{str(e)}")

        # å˜—è©¦ä½¿ç”¨å­—å¹•
        if video_url and output_dir:
            logger.info("å˜—è©¦å¾å­—å¹•æ–‡ä»¶è®€å–...")
            subtitle_text = extract_subtitles(video_url, output_dir)
            if subtitle_text:
                logger.info("æˆåŠŸè®€å–å­—å¹•æ–‡ä»¶")
                if output_dir:
                    try:
                        with open(transcript_path, 'w', encoding='utf-8') as f:
                            f.write(f"ä¾†æºï¼šå­—å¹•æ–‡ä»¶\n\n")
                            f.write(subtitle_text)
                    except Exception as e:
                        logger.warning(f"ä¿å­˜å­—å¹•å…§å®¹æ™‚å‡ºéŒ¯ï¼š{str(e)}")
                return subtitle_text

        logger.info("é–‹å§‹é€²è¡ŒèªéŸ³è¾¨è­˜...")

        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        model = get_whisper_model()

        # å‰è™•ç†éŸ³è¨Š
        audio_path = load_and_clean_audio(audio_path)

        # åˆ†æ®µ
        logger.info("é–‹å§‹åˆ†å‰²éŸ³é »...")
        segment_files = split_audio_for_transcription(
            audio_path,
            segment_duration=120,
            overlap=2,
            use_silence_detection=use_silence_detection,
            merge_gap_threshold=merge_gap_threshold,
            min_segment_duration=min_segment_duration
        )
        if not segment_files:
            raise Exception("éŸ³é »åˆ†å‰²å¤±æ•—")

        all_transcripts = []
        per_segment_languages = []
        total_segments = len(segment_files)

        for i, segment_path in enumerate(segment_files, 1):
            logger.info(f"æ­£åœ¨è½‰éŒ„ç¬¬ {i}/{total_segments} å€‹ç‰‡æ®µ...")
            try:
                segments, info = model.transcribe(
                    segment_path,
                    beam_size=5,
                    temperature=0.0,
                    vad_filter=False,
                    compression_ratio_threshold=5.0,
                    log_prob_threshold=-2.5,
                    no_speech_threshold=0.6,
                )

                segments = list(segments)
                transcript = "".join([s.text for s in segments]).strip()
                detected_language = info.language or "æœªçŸ¥"
                per_segment_languages.append(detected_language)

                if not transcript or len(transcript) < 10:
                    logger.warning(f"âš ï¸ ç¬¬ {i+1} æ®µå…§å®¹éçŸ­ï¼ˆ{len(transcript)} å­—å…ƒï¼‰ï¼Œç•¥é")
                    continue

                if is_excessive_repetition(transcript, phrase_threshold=20, length_threshold=0.8):
                    logger.warning(f"âš ï¸ ç¬¬ {i+1} æ®µå…§å®¹éåº¦é‡è¤‡ï¼ˆå¯èƒ½ç‚ºå¹»è¦ºï¼‰ï¼Œç•¥é")
                    continue
                
                # ğŸ§ ã€å®‰å…¨éæ¿¾ï¼šéåº¦é‡è¤‡ã€‘
                if any(transcript.count(phrase) >= 5 for phrase in [
                    "Thank you for watching",
                    "This is the first time I've ever seen",
                    "See you in the next video"
                ]):
                    logger.warning(f"âš ï¸ ç¬¬ {i} æ®µå‡ºç¾å¤§é‡é‡è¤‡èªå¥ï¼Œè¦–ç‚º hallucinationï¼Œç•¥é")
                    continue

                # ğŸš¨ã€èªè¨€ç•°å¸¸æé†’ï¼ˆä¸éæ¿¾ï¼‰ã€‘
                if detected_language not in {"zh", "en", "ja"}:
                    logger.warning(f"âš ï¸ èªè¨€åµæ¸¬ç•°å¸¸ï¼ˆ{detected_language}ï¼‰ï¼Œè«‹æª¢æŸ¥å…§å®¹åˆç†æ€§")

                # ğŸ“ è¨˜éŒ„æœ‰æ•ˆçµæœ
                all_transcripts.append(transcript)
                logger.info(f"ç¬¬ {i} æ®µè½‰éŒ„å®Œæˆï¼ˆèªè¨€: {detected_language}ï¼Œé•·åº¦: {len(transcript)}ï¼‰")

            except Exception as e:
                logger.error(f"è½‰éŒ„ç¬¬ {i} æ®µæ™‚å‡ºéŒ¯: {str(e)}")
                continue
            finally:
                try:
                    os.remove(segment_path)
                except:
                    pass


        final_transcript = merge_transcripts(all_transcripts)

        # å„²å­˜çµæœ
        if output_dir:
            try:
                with open(transcript_path, 'w', encoding='utf-8') as f:
                    f.write("ä¾†æºï¼šFaster-Whisper èªéŸ³è¾¨è­˜\n")
                    if track_languages:
                        lang_counter = {lang: per_segment_languages.count(lang) for lang in set(per_segment_languages)}
                        f.write(f"èªè¨€åˆ‡æ›çµ±è¨ˆï¼š{lang_counter}\n")
                        for idx, (text, lang) in enumerate(zip(all_transcripts, per_segment_languages)):
                            f.write(f"\n[{lang}] æ®µè½ {idx+1}:\n{text.strip()}\n")
                    else:
                        f.write(f"\nåµæ¸¬èªè¨€ï¼ˆé¦–æ®µï¼‰: {per_segment_languages[0] if per_segment_languages else 'æœªçŸ¥'}\n\n")
                        f.write(final_transcript)
                logger.info(f"è½‰éŒ„çµæœå·²å„²å­˜è‡³ï¼š{transcript_path}")
            except Exception as e:
                logger.warning(f"å„²å­˜è½‰éŒ„æ™‚å‡ºéŒ¯ï¼š{str(e)}")

        # æ¸…ç†æš«å­˜
        temp_dir = os.path.join(os.path.dirname(audio_path), "temp_segments")
        try:
            os.rmdir(temp_dir)
        except:
            pass

        return final_transcript

    except Exception as e:
        logger.error(f"è½‰éŒ„éŸ³è¨Šæ™‚å‡ºéŒ¯: {str(e)}")
        return ""
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def is_excessive_repetition(text: str, phrase_threshold: int = 20, length_threshold: float = 0.8):
    """
    æª¢æŸ¥è½‰éŒ„æ–‡æœ¬æ˜¯å¦å­˜åœ¨éåº¦é‡è¤‡çš„ä¸‰å­—è©ç‰‡æ®µã€‚
    å¦‚æœæŸå¥é‡è¤‡å‡ºç¾æ¬¡æ•¸ â‰¥ phrase_threshold æˆ–ä½”æ¯” â‰¥ length_thresholdï¼Œ
    è¿”å› Trueï¼Œå¦å‰‡è¿”å› Falseã€‚
    """
    words = text.split()
    total_len = len(words)
    if total_len < 6:
        return False  # å¤ªçŸ­ä¸åˆ¤å®š

    phrase_counts = {}
    for i in range(total_len - 2):
        phrase = " ".join(words[i:i+3])
        phrase_counts[phrase] = phrase_counts.get(phrase, 0) + 1

    max_phrase = max(phrase_counts, key=phrase_counts.get, default=None)
    if max_phrase:
        count = phrase_counts[max_phrase]
        ratio = (count * 3) / total_len  # è©²çŸ­èªæ‰€ä½”æ¯”ä¾‹
        # Debug è¼¸å‡º
        print(f"[DEBUG] Most repeated phrase: '{max_phrase}' appears {count} times, ratio: {ratio:.2f}")
        if count >= phrase_threshold or ratio >= length_threshold:
            return True
    return False



def compute_text_embedding(text: str) -> torch.Tensor:
    """è¨ˆç®—æ–‡æœ¬çš„åµŒå…¥å‘é‡"""
    try:
        # ç²å–æ¨¡å‹ï¼ˆä¸éœ€è¦é‡æ–°è¼‰å…¥ï¼‰
        model = get_sentence_transformer()
        
        # è¨ˆç®—åµŒå…¥å‘é‡
        with torch.no_grad():
            embeddings = model.encode(text, convert_to_tensor=True)
            logger.info("å·²å®Œæˆæ–‡æœ¬åµŒå…¥å‘é‡è¨ˆç®—")
        
        return embeddings
        
    except Exception as e:
        logger.error(f"è¨ˆç®—æ–‡æœ¬åµŒå…¥å‘é‡æ™‚å‡ºéŒ¯: {str(e)}")
        return None

def is_meaningful_text(text: str, min_length: int = 10) -> tuple:
    """
    åˆ¤æ–·æ–‡æœ¬æ˜¯å¦æœ‰æ„ç¾©ï¼Œä¸»è¦æª¢æŸ¥ï¼š
    1. æ˜¯å¦ç‚ºç©ºç™½æˆ–é•·åº¦éçŸ­
    2. æ˜¯å¦å­˜åœ¨å¤§é‡é‡è¤‡å…§å®¹ï¼ˆæ ¹æ“šæ–‡æœ¬é•·åº¦å‹•æ…‹èª¿æ•´ï¼‰
    
    åƒæ•¸:
        text: è¦åˆ†æçš„æ–‡æœ¬
        min_length: æœ€å°æ–‡æœ¬é•·åº¦
    
    è¿”å›:
        tuple: (æ˜¯å¦æœ‰æ„ç¾©, åŸå› æè¿°)
    """
    try:
        # æª¢æŸ¥ç©ºç™½
        if not text:
            return (False, "æ–‡æœ¬ç‚ºç©º")
        
        # ç§»é™¤å¤šé¤˜ç©ºç™½
        text = ' '.join(text.split())
        if not text:
            return (False, "æ–‡æœ¬åƒ…åŒ…å«ç©ºç™½å­—ç¬¦")
            
        # æª¢æŸ¥æœ€å°é•·åº¦
        if len(text) < min_length:
            return (False, f"æ–‡æœ¬é•·åº¦éçŸ­ ({len(text)} å­—ç¬¦)")
            
        # æª¢æŸ¥é‡è¤‡æ¨¡å¼ï¼ˆæ ¹æ“šæ–‡æœ¬é•·åº¦å‹•æ…‹èª¿æ•´ï¼‰
        text_length = len(text)
        
        # å®šç¾©é‡è¤‡æª¢æŸ¥çš„åƒæ•¸
        if text_length < 100:  # çŸ­æ–‡æœ¬
            pattern_length = 3
            repeat_times = 3
        elif text_length < 500:  # ä¸­ç­‰æ–‡æœ¬
            pattern_length = 5
            repeat_times = 4
        else:  # é•·æ–‡æœ¬
            pattern_length = 10
            repeat_times = 5
            
        # æª¢æŸ¥é‡è¤‡æ¨¡å¼
        pattern = f'(.{{{pattern_length},}}?)\\1{{{repeat_times-1},}}'
        matches = list(re.finditer(pattern, text))
        
        if matches:
            # è¨ˆç®—é‡è¤‡å…§å®¹ä½”ç¸½æ–‡æœ¬çš„æ¯”ä¾‹
            total_repeated_length = sum(len(m.group(0)) for m in matches)
            repeat_ratio = total_repeated_length / text_length
            
            # å¦‚æœé‡è¤‡å…§å®¹è¶…éæ–‡æœ¬çš„ 70%ï¼Œåˆ¤å®šç‚ºç„¡æ„ç¾©
            if repeat_ratio > 0.7:
                repeated_examples = [m.group(1) for m in matches[:3]]  # å–å‰ä¸‰å€‹é‡è¤‡ç¤ºä¾‹
                return (False, f"å­˜åœ¨å¤§é‡é‡è¤‡å…§å®¹ï¼ˆä½”æ¯” {repeat_ratio:.1%}ï¼‰ï¼Œä¾‹å¦‚ï¼š{', '.join(repeated_examples)}")
        
        return (True, "æ–‡æœ¬æœ‰æ•ˆ")
        
    except Exception as e:
        logger.error(f"åˆ¤æ–·æ–‡æœ¬æ„ç¾©æ™‚å‡ºéŒ¯: {str(e)}")
        return (False, f"éŒ¯èª¤: {str(e)}")

def text_similarity(text1: str, text2: str) -> tuple:
    """
    è¨ˆç®—æ–‡å­—ç›¸ä¼¼åº¦
    
    è¿”å›:
        tuple: (ç›¸ä¼¼åº¦åˆ†æ•¸, æ˜¯å¦æœ‰æ•ˆæ¯”å°, ç‹€æ…‹èªªæ˜)
    """
    try:
        # å¦‚æœæ–‡å­—ç‚ºç©ºï¼Œè¿”å› 0
        if not text1 or not text2:
            logger.warning("æ–‡å­—ç‚ºç©ºï¼Œè¿”å›ç›¸ä¼¼åº¦ 0")
            return (0.0, False, "æ–‡æœ¬ç‚ºç©º")
            
        # åˆ¤æ–·å…©æ®µæ–‡æœ¬æ˜¯å¦æœ‰æ„ç¾©
        text1_meaningful, text1_reason = is_meaningful_text(text1)
        text2_meaningful, text2_reason = is_meaningful_text(text2)
        
        # å¦‚æœä»»ä¸€æ–‡æœ¬ç„¡æ„ç¾©ï¼Œè¿”å›è©³ç´°åŸå› 
        if not text1_meaningful or not text2_meaningful:
            reasons = []
            if not text1_meaningful:
                reasons.append(f"æ–‡æœ¬1: {text1_reason}")
            if not text2_meaningful:
                reasons.append(f"æ–‡æœ¬2: {text2_reason}")
            logger.warning(f"æª¢æ¸¬åˆ°ç„¡æ„ç¾©æ–‡æœ¬: {'; '.join(reasons)}")
            return (0.0, False, "; ".join(reasons))
            
        logger.info("é–‹å§‹è¨ˆç®—æ–‡æœ¬ç›¸ä¼¼åº¦...")
        
        # è¨ˆç®—åµŒå…¥å‘é‡
        emb1 = compute_text_embedding(text1)
        emb2 = compute_text_embedding(text2)
        
        if emb1 is None or emb2 is None:
            return (0.0, False, "åµŒå…¥å‘é‡è¨ˆç®—å¤±æ•—")
        
        # è¨ˆç®—ç›¸ä¼¼åº¦
        with torch.no_grad():
            similarity = util.pytorch_cos_sim(emb1, emb2)[0][0].item()
        
        # æ ¹æ“šæ–‡æœ¬é•·åº¦èª¿æ•´æ¬Šé‡
        len_ratio = min(len(text1), len(text2)) / max(len(text1), len(text2))
        adjusted_similarity = similarity * (0.7 + 0.3 * len_ratio)  # é•·åº¦å·®ç•°å½±éŸ¿30%çš„æ¬Šé‡
        
        logger.info(f"æ–‡æœ¬ç›¸ä¼¼åº¦è¨ˆç®—å®Œæˆ: åŸå§‹={similarity:.4f}, èª¿æ•´å¾Œ={adjusted_similarity:.4f}")
        return (float(adjusted_similarity), True, f"æœ‰æ•ˆæ¯”å°ï¼Œé•·åº¦æ¯”ä¾‹={len_ratio:.2f}")
        
    except Exception as e:
        logger.error(f"è¨ˆç®—æ–‡æœ¬ç›¸ä¼¼åº¦æ™‚å‡ºéŒ¯: {str(e)}")
        return (0.0, False, f"éŒ¯èª¤: {str(e)}")
    finally:
        # ç¢ºä¿æ¸…ç†æ‰€æœ‰è³‡æº
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.info("æœ€çµ‚æ¸…ç† GPU è¨˜æ†¶é«”å®Œæˆ")